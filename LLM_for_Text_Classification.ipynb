{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn0+fogpZUhqA6KGQR0X1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rainfireliang/COMM6320_IntroductionR/blob/master/LLM_for_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Tutorial for Text Classification using OpenAI"
      ],
      "metadata": {
        "id": "fposYNqlFgL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hai Liang, 2022/11/24\n",
        "\n",
        "The Chinese University of Hong Kong\n",
        "\n",
        "hailiang@cuhk.edu.hk\n",
        "\n",
        "https://drhailiang.com/"
      ],
      "metadata": {
        "id": "3DvV-DltmfwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation\n",
        "\n",
        "Using pip to install OpenAI:"
      ],
      "metadata": {
        "id": "jjF1yUSeFtIf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUk9P-ErdJSD"
      },
      "outputs": [],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to create an OpenAI API key. Please follow the steps stated here: https://www.maisieai.com/help/how-to-get-an-openai-api-key-for-chatgpt. Using the following function to input the API key."
      ],
      "metadata": {
        "id": "Pu63TFTSF1XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key=\"sk-xxx\",\n",
        ")\n",
        "\n",
        "# an example of creating a completion:\n",
        "completion = client.completions.create(model='curie', prompt=\"Hello, world!\")\n",
        "\n",
        "# these are methods to check the content of returned completions:\n",
        "print(completion.choices[0].text)\n",
        "print(dict(completion).get('usage'))\n",
        "print(completion.model_dump_json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg8yZB9sdhQ8",
        "outputId": "0acda566-91ec-45a6-c1c6-2f953ed4c7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "” >> circle.distribute(); call;\n",
            "\n",
            "Connection management\n",
            "\n",
            "\n",
            "CompletionUsage(completion_tokens=16, prompt_tokens=4, total_tokens=20)\n",
            "{\n",
            "  \"id\": \"cmpl-8Sy6N2PqvV7j89TKiNPNwDW8XPXry\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"\\u201d >> circle.distribute(); call;\\n\\nConnection management\\n\\n\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1701914907,\n",
            "  \"model\": \"curie\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 16,\n",
            "    \"prompt_tokens\": 4,\n",
            "    \"total_tokens\": 20\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-shot Text Classification\n",
        "\n",
        "It means that we can classify the text without training the model. We use sentiment analysis of IMDB movie reviews as an example.\n",
        "\n",
        "The basic logic is to \"prompt\" the ChatGPT to classify the text as positive or negative. The prompt text would be something similar to the below."
      ],
      "metadata": {
        "id": "2N-X03mVGpdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"\"\"What is the sentiment expressed in the following IMDB movie review? Select sentiment value from positive or negative. \\n\n",
        "Return only the sentiment value. Movie review: {}\"\"\".format(\"the movie is great\")\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jWv93nWJ_dK",
        "outputId": "3ae9c204-d359-4695-b190-3bfa8b7f510b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the sentiment expressed in the following IMDB movie review? Select sentiment value from positive or negative. \n",
            "\n",
            "Return only the sentiment value. Movie review: the movie is great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can create a completion, using the GPT3.5 model. You can use \"gpt-4\" with higher accuracy but more expensive."
      ],
      "metadata": {
        "id": "5v-fThzDKanQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": content,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\", # gpt-4\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# print the returned results\n",
        "print(sentiment.model_dump_json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXW7nW-9KZ0k",
        "outputId": "b85b8935-ba0e-4056-9b20-cb227c0fc085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8Sy6OBjmhfgafIuLIw6sWrRxhPvH5\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"positive\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1701914908,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 1,\n",
            "    \"prompt_tokens\": 42,\n",
            "    \"total_tokens\": 43\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The completion returned \"positive\": sentiment -> choices[0] -> message -> content.\n"
      ],
      "metadata": {
        "id": "_KDYJJ6pLp9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (sentiment.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PAlGkVkLc2j",
        "outputId": "f34bf45a-5d6b-4f6b-ae86-09e0f3cb7420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put all together, we can create a function to find the sentiment:"
      ],
      "metadata": {
        "id": "hlSSqJWbL5l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_sentiment(text):\n",
        "    content = \"\"\"What is the sentiment expressed in the following IMDB movie review?\n",
        "    Select sentiment value from positive or negative.\n",
        "    Return only the sentiment value. Movie review: {}\"\"\".format(text)\n",
        "    sentiment = client.chat.completions.create(\n",
        "        messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": content,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    )\n",
        "    return sentiment.choices[0].message.content"
      ],
      "metadata": {
        "id": "DZBxKLZ080Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it out."
      ],
      "metadata": {
        "id": "R0DZR5NmL9IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(find_sentiment(\"the movie is terrible\"))\n",
        "print(find_sentiment(\"the movie is great\"))\n",
        "print(find_sentiment(\"\"\"I think I'm glad I did not read the book,\n",
        "because what I watched was nothing short of wonderful in every \"facet\".\n",
        "Mark Ruffalo and the sparsely seen Hugh Laurie were fantastic,\n",
        "but still a notch or two below the magnificent Aria Mia Loberti in her premier performance.\n",
        "And as a huge fan of the German series \"Dark\", I grinned wide when Louis Hoffman was on the screen.\n",
        "Great screenplay (IMO), photography, music...it is all very memorable. With just four episodes, I imagine I will eventually watch again.\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWGHjIJDBzva",
        "outputId": "48cdd833-d1e2-44d6-ba9a-e3768cc8f742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n",
            "positive\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More examples in Chinese"
      ],
      "metadata": {
        "id": "XQndIBJfL_c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(find_sentiment(\"\"\"A clean miss, one hopes Allied bombs landed truer than this melodramatic mush.\"\"\"))\n",
        "print(find_sentiment(\"\"\"無敵爛片、無聊透頂\"\"\"))\n",
        "print(find_sentiment(\"\"\"一部略帶憂傷的影片，將人世間的苦楚敘述得入木三分\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QXJGWm_Da_J",
        "outputId": "90b44974-e8d2-4ab7-a43f-65243ffc8bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n",
            "negative\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-shot Text Classification\n",
        "It means that we can classify the text with a few training examples."
      ],
      "metadata": {
        "id": "7zOXMCOCNgBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [(\"A clean miss, one hopes Allied bombs landed truer than this melodramatic mush.\", \"positive\"),\n",
        " (\"無敵爛片、無聊透頂\", \"negative\"),(\"一部略帶憂傷的影片，將人世間的苦楚敘述得入木三分\", \"positive\")]\n",
        "\n",
        "\n",
        "prompt_1 = \"\"\"What is the sentiment expressed in the following IMDB movie review?\n",
        "  Select sentiment value from positive or negative. \\n\n",
        "  Return only the sentiment value. And I will show a few examples with texts and\n",
        "  the sentiment in a list of brackets:{}\"\"\".format(examples)\n",
        "\n",
        "prompt_2 = \"\"\"The Movie review is: {}\"\"\".format(\"the movie is great\")\n",
        "\n",
        "content = prompt_1 + \"\\n\" + prompt_2\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "id": "huJEZldCNuOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdec26f-ce9d-4b87-afa7-d270ec840f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the sentiment expressed in the following IMDB movie review?\n",
            "  Select sentiment value from positive or negative. \n",
            "\n",
            "  Return only the sentiment value. And I will show a few examples with texts and\n",
            "  the sentiment in a list of brackets:[('A clean miss, one hopes Allied bombs landed truer than this melodramatic mush.', 'positive'), ('無敵爛片、無聊透頂', 'negative'), ('一部略帶憂傷的影片，將人世間的苦楚敘述得入木三分', 'positive')]\n",
            "The Movie review is: the movie is great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_sentiment_few(text):\n",
        "    content = prompt_1 + \"\\n\" + \"\"\"The Movie review is: {}\"\"\".format(text)\n",
        "    sentiment = client.chat.completions.create(\n",
        "        messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": content,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    )\n",
        "    return sentiment.choices[0].message.content"
      ],
      "metadata": {
        "id": "NbupubExZ221"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(find_sentiment_few(\"the movie is terrible\"))\n",
        "print(find_sentiment_few(\"一部略帶憂傷的影片，將人世間的苦楚敘述得入木三分\"))\n",
        "print(find_sentiment_few(\"這部戲劇是一部略帶憂傷的影片，將人世間的苦楚敘述得入木三分\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5AujXbiaNv6",
        "outputId": "6e95d4bc-1e1d-49b9-9e1f-602600168d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n",
            "positive\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification with Fine Tuning\n",
        "It means that we can fine-tune the pre-trained GPT models to classify the text. Please check the offical webpage: https://platform.openai.com/docs/guides/fine-tuning.\n",
        "\n",
        "Fine-tuning is currently available for the following models:\n",
        "\n",
        "* gpt-3.5-turbo-1106 (recommended)\n",
        "* gpt-3.5-turbo-0613\n",
        "* babbage-002\n",
        "* davinci-002\n",
        "* gpt-4-0613 (experimental — eligible users will be presented with an option to request access in the fine-tuning UI)"
      ],
      "metadata": {
        "id": "r-m1BAgolnih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-llm"
      ],
      "metadata": {
        "id": "Fiu5K9wkl1na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm.config import SKLLMConfig\n",
        "SKLLMConfig.set_openai_key(\"sk-xxx\")"
      ],
      "metadata": {
        "id": "IcJ4fcUrUSC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm.datasets import get_classification_dataset\n",
        "X, y = get_classification_dataset()"
      ],
      "metadata": {
        "id": "3vXEGk3lQHZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rTbpDLfQVT-",
        "outputId": "dc58996f-59dc-4c16-b9ca-3b09c216e941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm.models.gpt import GPTClassifier\n",
        "\n",
        "clf = GPTClassifier(\n",
        "        base_model = \"gpt-3.5-turbo-0613\",\n",
        "        n_epochs = None, # int or None. When None, will be determined automatically by OpenAI\n",
        "        default_label = \"Random\", # optional\n",
        ")\n",
        "\n",
        "clf.fit(X,y) # y_train is a list of labels\n",
        "labels = clf.predict(X[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSMezMmmPu2R",
        "outputId": "947c66d6-2be8-489c-e3f2-bb099b1304b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new file. FILE_ID = file-SBMLkvrtMiOyUCpOY6lbG6G9\n",
            "Waiting for file to be processed ...\n",
            "Created new tuning job. JOB_ID = ftjob-2X52tW1Kxl1v9LySb3bbpNZr\n",
            "[2023-12-07 02:10:21.883787] Waiting for tuning job to complete. Current status: validating_files\n",
            "[2023-12-07 02:12:22.065627] Waiting for tuning job to complete. Current status: running\n",
            "[2023-12-07 02:14:22.356142] Waiting for tuning job to complete. Current status: running\n",
            "Finished training. Number of trained tokens: 19323.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:06<00:00,  1.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRyNYO4sdFoQ",
        "outputId": "cedee65f-c96f-44c8-d842-ec41fc2d1598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}